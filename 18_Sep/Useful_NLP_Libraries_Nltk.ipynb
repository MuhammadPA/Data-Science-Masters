{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6js74YnwlqeN"
      },
      "source": [
        "# Importing neccessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFxVmLR-lqep",
        "outputId": "b75fd607-2f73-4cff-c324-15bceac518db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in c:\\users\\manisha\\anaconda3\\lib\\site-packages (3.5)\n",
            "Requirement already satisfied: tqdm in c:\\users\\manisha\\anaconda3\\lib\\site-packages (from nltk) (4.50.2)\n",
            "Requirement already satisfied: regex in c:\\users\\manisha\\anaconda3\\lib\\site-packages (from nltk) (2020.10.15)\n",
            "Requirement already satisfied: click in c:\\users\\manisha\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in c:\\users\\manisha\\anaconda3\\lib\\site-packages (from nltk) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "# Install NLTK using pip\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7YQgePslqe6",
        "outputId": "4f17d2fa-eb55-4a6e-c435-f5ae026d3474"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Manisha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\Manisha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     C:\\Users\\Manisha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to\n",
            "[nltk_data]     C:\\Users\\Manisha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import NLTK\n",
        "import nltk\n",
        "# Download necessary resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1diAK8-lqe-"
      },
      "source": [
        "# Sample text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI23SemUlqfA"
      },
      "outputs": [],
      "source": [
        "text = \"NLTK is a powerful tool for natural language processing. It can tokenize sentences and words. NLTK includes various NLP libraries for text analysis.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ing71gVUlqfB"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WamKld9UlqfC",
        "outputId": "327148d2-e5d3-4849-e04b-a2425610c349"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words: ['NLTK', 'is', 'a', 'powerful', 'tool', 'for', 'natural', 'language', 'processing', '.', 'It', 'can', 'tokenize', 'sentences', 'and', 'words', '.', 'NLTK', 'includes', 'various', 'NLP', 'libraries', 'for', 'text', 'analysis', '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "sentences = sent_tokenize(text)\n",
        "words = word_tokenize(text)\n",
        "print(\"Words:\", words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZRLL-JslqfI"
      },
      "source": [
        "# Part-of-speech tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiQRDN7ilqfM",
        "outputId": "2e057427-da4b-4729-c10c-ed71ef182bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "POS Tags: [('NLTK', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('powerful', 'JJ'), ('tool', 'NN'), ('for', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('.', '.'), ('It', 'PRP'), ('can', 'MD'), ('tokenize', 'VB'), ('sentences', 'NNS'), ('and', 'CC'), ('words', 'NNS'), ('.', '.'), ('NLTK', 'NNP'), ('includes', 'VBZ'), ('various', 'JJ'), ('NLP', 'NNP'), ('libraries', 'NNS'), ('for', 'IN'), ('text', 'JJ'), ('analysis', 'NN'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "from nltk import pos_tag\n",
        "\n",
        "pos_tags = pos_tag(words)\n",
        "print(\"POS Tags:\", pos_tags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufB--AyUlqfO"
      },
      "source": [
        "# Stemming and Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDnhXRp0lqfS",
        "outputId": "160a94e0-5ed9-4029-afe7-d766cf2c496d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stemmed Words: ['nltk', 'is', 'a', 'power', 'tool', 'for', 'natur', 'languag', 'process', '.', 'It', 'can', 'token', 'sentenc', 'and', 'word', '.', 'nltk', 'includ', 'variou', 'nlp', 'librari', 'for', 'text', 'analysi', '.']\n",
            "Lemmatized Words: ['NLTK', 'is', 'a', 'powerful', 'tool', 'for', 'natural', 'language', 'processing', '.', 'It', 'can', 'tokenize', 'sentence', 'and', 'word', '.', 'NLTK', 'includes', 'various', 'NLP', 'library', 'for', 'text', 'analysis', '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "print(\"Stemmed Words:\", stemmed_words)\n",
        "print(\"Lemmatized Words:\", lemmatized_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZBeoIwdlqfT"
      },
      "source": [
        "# Stop words removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sHu3p09lqfg",
        "outputId": "2a3f4a5c-c412-40b8-cc57-04e90bbc96ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered Words: ['NLTK', 'powerful', 'tool', 'natural', 'language', 'processing', '.', 'tokenize', 'sentences', 'words', '.', 'NLTK', 'includes', 'various', 'NLP', 'libraries', 'text', 'analysis', '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "print(\"Filtered Words:\", filtered_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8K1X-YYlqfh"
      },
      "source": [
        "# Frequency Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfPgiQc9lqfi",
        "outputId": "3e901105-9e9d-481b-bd49-d7c76a460800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frequency Distribution: <FreqDist with 22 samples and 26 outcomes>\n"
          ]
        }
      ],
      "source": [
        "from nltk import FreqDist\n",
        "\n",
        "freq_dist = FreqDist(words)\n",
        "print(\"Frequency Distribution:\", freq_dist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7Xui1m9lqfj"
      },
      "source": [
        "# Concordance and Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IgprUH5lqfk",
        "outputId": "2e82a7bd-5c01-4f07-c622-338c399a0c4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Displaying 2 of 2 matches:\n",
            " NLTK is a powerful tool for natural langu\n",
            "t can tokenize sentences and words . NLTK includes various NLP libraries for t\n",
            "\n",
            "Concordance Result: None\n",
            "Similar Words: None\n"
          ]
        }
      ],
      "source": [
        "from nltk.text import Text\n",
        "\n",
        "text_object = Text(words)\n",
        "concordance_result = text_object.concordance(\"NLTK\")\n",
        "similar_words = text_object.similar(\"tool\")\n",
        "print(\"Concordance Result:\", concordance_result)\n",
        "print(\"Similar Words:\", similar_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EMYqS7zlqfn"
      },
      "source": [
        "# Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xemdn4vFlqfq",
        "outputId": "0f62ca0b-bcbd-4331-ce6b-9f1e62cf612c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment Analysis Score: {'neg': 0.0, 'neu': 0.745, 'pos': 0.255, 'compound': 0.6705}\n"
          ]
        }
      ],
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "sentiment_score = sia.polarity_scores(text)\n",
        "print(\"Sentiment Analysis Score:\", sentiment_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V3fkGgklqft"
      },
      "source": [
        "# Named Entity Recognition (NER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZ2msRhulqfu",
        "outputId": "98045a7d-fc31-4725-c2c0-2e0956e132e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NER Result: (S\n",
            "  (ORGANIZATION NLTK/NNP)\n",
            "  is/VBZ\n",
            "  a/DT\n",
            "  powerful/JJ\n",
            "  tool/NN\n",
            "  for/IN\n",
            "  natural/JJ\n",
            "  language/NN\n",
            "  processing/NN\n",
            "  ./.\n",
            "  It/PRP\n",
            "  can/MD\n",
            "  tokenize/VB\n",
            "  sentences/NNS\n",
            "  and/CC\n",
            "  words/NNS\n",
            "  ./.\n",
            "  (ORGANIZATION NLTK/NNP)\n",
            "  includes/VBZ\n",
            "  various/JJ\n",
            "  (ORGANIZATION NLP/NNP)\n",
            "  libraries/NNS\n",
            "  for/IN\n",
            "  text/JJ\n",
            "  analysis/NN\n",
            "  ./.)\n"
          ]
        }
      ],
      "source": [
        "from nltk import ne_chunk\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "pos_tags_for_ner = pos_tag(tokens)\n",
        "ner_result = ne_chunk(pos_tags_for_ner)\n",
        "print(\"NER Result:\", ner_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nvp4jh8Alqfx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}